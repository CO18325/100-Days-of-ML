## KNN (K Nearest Neighbors)

KNN is the laziest algorithm out there in machine learning

It works in a very simple way by taking into account the distances from unknown data point. After we gather K neighbours,we simply take the majority and classify the unknown data into that category.

It classifies the new data or case based on a similarity measure. There fore it is used in search applications that is when you are looking for the similarities in different items.
 
What is this K in KNN? 

> K is the no. of Nearest Neighbor in graph

Industrial Use case of KNN algorithm:

1. The biggest example is the recommendation system, Amazons 35% of the revenue is generated by this recommendation system as it shows the products people used to buy based on their previous searches.

2. The second biggest application is Concept Search or searching semantically similar documents containing similar topics.

3. It is recently being used in Image detection, Hand-writing detection, OCR detection and Audio detection

How Does it work ?
 
To start classification firstly we have to predict the minimum value of k for the new unknown point we have to classify then we will calculate the distance of this unknown point from each point in nearest neighbors.

It works on two distance algorithms :

1. Euclidean Distance: It is the direct distance between the two points or you can say that euclidean distance is the minimum possible distance between two points

2. Manhattan distance: It is the distance between two real vectors in a plane measured along the right angles.